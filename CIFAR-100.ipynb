{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ce1b882",
   "metadata": {},
   "source": [
    "# <center>CIFAR-100</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68933404",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Librairies-Import\" data-toc-modified-id=\"Librairies-Import-1\">Librairies Import</a></span></li><li><span><a href=\"#Dataset-Loading\" data-toc-modified-id=\"Dataset-Loading-2\">Dataset Loading</a></span></li><li><span><a href=\"#Normalization\" data-toc-modified-id=\"Normalization-3\">Normalization</a></span></li><li><span><a href=\"#DataModule\" data-toc-modified-id=\"DataModule-4\">DataModule</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-5\">Model</a></span></li><li><span><a href=\"#Lightning-Pipeline\" data-toc-modified-id=\"Lightning-Pipeline-6\">Lightning Pipeline</a></span></li><li><span><a href=\"#Model-Training-and-Evaluation\" data-toc-modified-id=\"Model-Training-and-Evaluation-7\">Model Training and Evaluation</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72bc54e",
   "metadata": {},
   "source": [
    "## Librairies Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "628aa0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import OneCycleLR, ReduceLROnPlateau\n",
    "import torchvision\n",
    "from torchvision.utils import make_grid\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from torchmetrics.functional import accuracy\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import LightningModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09108bb",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40458a0",
   "metadata": {},
   "source": [
    "We start by downloading the train and test sets of CIFAR-100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ae5cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_set = torchvision.datasets.CIFAR100(root=\"./data\", download=True, train=True, transform=train_transform)\n",
    "test_set = torchvision.datasets.CIFAR100(root=\"./data\", download=True, train=False, transform=test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11775047",
   "metadata": {},
   "source": [
    "We then calculate the number of images by class for each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "421264da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cattle': 500,\n",
       " 'dinosaur': 500,\n",
       " 'apple': 500,\n",
       " 'boy': 500,\n",
       " 'aquarium_fish': 500,\n",
       " 'telephone': 500,\n",
       " 'train': 500,\n",
       " 'cup': 500,\n",
       " 'cloud': 500,\n",
       " 'elephant': 500,\n",
       " 'keyboard': 500,\n",
       " 'willow_tree': 500,\n",
       " 'sunflower': 500,\n",
       " 'castle': 500,\n",
       " 'sea': 500,\n",
       " 'bicycle': 500,\n",
       " 'wolf': 500,\n",
       " 'squirrel': 500,\n",
       " 'shrew': 500,\n",
       " 'pine_tree': 500,\n",
       " 'rose': 500,\n",
       " 'television': 500,\n",
       " 'table': 500,\n",
       " 'possum': 500,\n",
       " 'oak_tree': 500,\n",
       " 'leopard': 500,\n",
       " 'maple_tree': 500,\n",
       " 'rabbit': 500,\n",
       " 'chimpanzee': 500,\n",
       " 'clock': 500,\n",
       " 'streetcar': 500,\n",
       " 'cockroach': 500,\n",
       " 'snake': 500,\n",
       " 'lobster': 500,\n",
       " 'mountain': 500,\n",
       " 'palm_tree': 500,\n",
       " 'skyscraper': 500,\n",
       " 'tractor': 500,\n",
       " 'shark': 500,\n",
       " 'butterfly': 500,\n",
       " 'bottle': 500,\n",
       " 'bee': 500,\n",
       " 'chair': 500,\n",
       " 'woman': 500,\n",
       " 'hamster': 500,\n",
       " 'otter': 500,\n",
       " 'seal': 500,\n",
       " 'lion': 500,\n",
       " 'mushroom': 500,\n",
       " 'girl': 500,\n",
       " 'sweet_pepper': 500,\n",
       " 'forest': 500,\n",
       " 'crocodile': 500,\n",
       " 'orange': 500,\n",
       " 'tulip': 500,\n",
       " 'mouse': 500,\n",
       " 'camel': 500,\n",
       " 'caterpillar': 500,\n",
       " 'man': 500,\n",
       " 'skunk': 500,\n",
       " 'kangaroo': 500,\n",
       " 'raccoon': 500,\n",
       " 'snail': 500,\n",
       " 'rocket': 500,\n",
       " 'whale': 500,\n",
       " 'worm': 500,\n",
       " 'turtle': 500,\n",
       " 'beaver': 500,\n",
       " 'plate': 500,\n",
       " 'wardrobe': 500,\n",
       " 'road': 500,\n",
       " 'fox': 500,\n",
       " 'flatfish': 500,\n",
       " 'tiger': 500,\n",
       " 'ray': 500,\n",
       " 'dolphin': 500,\n",
       " 'poppy': 500,\n",
       " 'porcupine': 500,\n",
       " 'lamp': 500,\n",
       " 'crab': 500,\n",
       " 'motorcycle': 500,\n",
       " 'spider': 500,\n",
       " 'tank': 500,\n",
       " 'orchid': 500,\n",
       " 'lizard': 500,\n",
       " 'beetle': 500,\n",
       " 'bridge': 500,\n",
       " 'baby': 500,\n",
       " 'lawn_mower': 500,\n",
       " 'house': 500,\n",
       " 'bus': 500,\n",
       " 'couch': 500,\n",
       " 'bowl': 500,\n",
       " 'pear': 500,\n",
       " 'bed': 500,\n",
       " 'plain': 500,\n",
       " 'trout': 500,\n",
       " 'bear': 500,\n",
       " 'pickup_truck': 500,\n",
       " 'can': 500}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classes_counts = {}\n",
    "\n",
    "for image in train_set:\n",
    "    label = train_set.classes[image[1]]\n",
    "    if label not in train_classes_counts:\n",
    "        train_classes_counts[label] = 1\n",
    "    else:\n",
    "        train_classes_counts[label] += 1\n",
    "\n",
    "train_classes_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3de67b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mountain': 100,\n",
       " 'forest': 100,\n",
       " 'seal': 100,\n",
       " 'mushroom': 100,\n",
       " 'sea': 100,\n",
       " 'tulip': 100,\n",
       " 'camel': 100,\n",
       " 'butterfly': 100,\n",
       " 'cloud': 100,\n",
       " 'apple': 100,\n",
       " 'skunk': 100,\n",
       " 'streetcar': 100,\n",
       " 'rocket': 100,\n",
       " 'lamp': 100,\n",
       " 'lion': 100,\n",
       " 'wolf': 100,\n",
       " 'rose': 100,\n",
       " 'orange': 100,\n",
       " 'dinosaur': 100,\n",
       " 'chimpanzee': 100,\n",
       " 'can': 100,\n",
       " 'keyboard': 100,\n",
       " 'bicycle': 100,\n",
       " 'chair': 100,\n",
       " 'plate': 100,\n",
       " 'lawn_mower': 100,\n",
       " 'turtle': 100,\n",
       " 'palm_tree': 100,\n",
       " 'shark': 100,\n",
       " 'pickup_truck': 100,\n",
       " 'boy': 100,\n",
       " 'couch': 100,\n",
       " 'house': 100,\n",
       " 'porcupine': 100,\n",
       " 'cockroach': 100,\n",
       " 'clock': 100,\n",
       " 'castle': 100,\n",
       " 'beaver': 100,\n",
       " 'bee': 100,\n",
       " 'bottle': 100,\n",
       " 'pear': 100,\n",
       " 'baby': 100,\n",
       " 'flatfish': 100,\n",
       " 'oak_tree': 100,\n",
       " 'leopard': 100,\n",
       " 'snail': 100,\n",
       " 'crocodile': 100,\n",
       " 'rabbit': 100,\n",
       " 'beetle': 100,\n",
       " 'girl': 100,\n",
       " 'sunflower': 100,\n",
       " 'raccoon': 100,\n",
       " 'train': 100,\n",
       " 'ray': 100,\n",
       " 'trout': 100,\n",
       " 'bowl': 100,\n",
       " 'snake': 100,\n",
       " 'orchid': 100,\n",
       " 'tractor': 100,\n",
       " 'caterpillar': 100,\n",
       " 'bus': 100,\n",
       " 'mouse': 100,\n",
       " 'crab': 100,\n",
       " 'sweet_pepper': 100,\n",
       " 'maple_tree': 100,\n",
       " 'whale': 100,\n",
       " 'skyscraper': 100,\n",
       " 'pine_tree': 100,\n",
       " 'tank': 100,\n",
       " 'cattle': 100,\n",
       " 'man': 100,\n",
       " 'aquarium_fish': 100,\n",
       " 'shrew': 100,\n",
       " 'plain': 100,\n",
       " 'possum': 100,\n",
       " 'lobster': 100,\n",
       " 'hamster': 100,\n",
       " 'television': 100,\n",
       " 'dolphin': 100,\n",
       " 'worm': 100,\n",
       " 'squirrel': 100,\n",
       " 'cup': 100,\n",
       " 'woman': 100,\n",
       " 'bridge': 100,\n",
       " 'wardrobe': 100,\n",
       " 'road': 100,\n",
       " 'lizard': 100,\n",
       " 'elephant': 100,\n",
       " 'spider': 100,\n",
       " 'fox': 100,\n",
       " 'otter': 100,\n",
       " 'poppy': 100,\n",
       " 'willow_tree': 100,\n",
       " 'table': 100,\n",
       " 'kangaroo': 100,\n",
       " 'telephone': 100,\n",
       " 'bed': 100,\n",
       " 'motorcycle': 100,\n",
       " 'bear': 100,\n",
       " 'tiger': 100}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes_counts = {}\n",
    "\n",
    "for image in test_set:\n",
    "    label = test_set.classes[image[1]]\n",
    "    if label not in test_classes_counts:\n",
    "        test_classes_counts[label] = 1\n",
    "    else:\n",
    "        test_classes_counts[label] += 1\n",
    "        \n",
    "test_classes_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56c6ea5",
   "metadata": {},
   "source": [
    "The train and test sets both feature the 100 classes to predict and are well-balanced, each class having 500 images in the train set and 100 images in the test set.\n",
    "\n",
    "We decide to further split the train set in a train and a validation set. We will extract 10% of the train set images for that. This is done in the `CIFAR100DataModule`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853bd565",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1648a0e",
   "metadata": {},
   "source": [
    "We create a function to compute the normalization statistics for our dataset. These statistics are computed on the train set and applied to the train, validation and test sets.\n",
    "The function is called in the `setup` method of the `CIFAR100DataModule`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c974fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normstats(train_set):\n",
    "    \"\"\"\n",
    "    Function to compute the normalization statistics on the train set.\n",
    "    \n",
    "    Takes in: train_set\n",
    "\n",
    "    Returns: (red channel mean, green channel mean, blue channel mean), (red channel std, green channel std, blue channel std)\n",
    "    \"\"\"\n",
    "    red_channels = torch.stack([train_set[i][0][0, :, :] for i in range(len(train_set))], dim=0)\n",
    "    green_channels = torch.stack([train_set[i][0][1, :, :] for i in range(len(train_set))], dim=0)\n",
    "    blue_channels = torch.stack([train_set[i][0][2, :, :] for i in range(len(train_set))], dim=0)\n",
    "    train_set_mean = (red_channels.mean().item(), green_channels.mean().item(), blue_channels.mean().item())\n",
    "    train_set_std = (red_channels.std().item(), green_channels.std().item(), blue_channels.std().item())\n",
    "    return train_set_mean, train_set_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7706fe18",
   "metadata": {},
   "source": [
    "## DataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e15278",
   "metadata": {},
   "source": [
    "Next, we create the DataModule. This class implements several methods to:\n",
    "- download the dataset (if not already done)\n",
    "- create the train, validation and test sets and apply all the necessary transforms (including data augmentation)\n",
    "- create the dataloaders\n",
    "\n",
    "In the `setup` method, we split the train set in a train and a validation set. This is done by picking 10% of the train images indices at random, after they are being shuffled. A seed is set prior to it and we ensured that it gave us a well-enough balanced validation set featuring all the 100 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "037a6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR100DataModule(LightningDataModule):\n",
    "    def __init__(self, batch_size=64, num_workers=2):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "    \n",
    "    \n",
    "    def prepare_data(self):\n",
    "        datasets.CIFAR100(root=\"./data\", download=True, train=True)\n",
    "        datasets.CIFAR100(root=\"./data\", download=True, train=False)\n",
    "\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        train_set = datasets.CIFAR100(root=\"./data\", train=True, transform=transforms.ToTensor())\n",
    "        train_set_mean, train_set_std = compute_normstats(train_set)\n",
    "        train_set_transforms = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
    "                                            transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                            transforms.RandomRotation(degrees=15),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize(train_set_mean, train_set_std, inplace=True)])\n",
    "\n",
    "        validation_set_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                            transforms.Normalize(train_set_mean, train_set_std, inplace=True)])                                            \n",
    "\n",
    "        test_set_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                            transforms.Normalize(train_set_mean, train_set_std, inplace=True)])\n",
    "\n",
    "        \n",
    "        # Get the train set images indices and shuffle them\n",
    "        train_set_length = len(train_set)\n",
    "        indices = list(range(train_set_length))\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        # Calculate the split point to have 10% of the train set as a validation set\n",
    "        split = int(np.floor(0.9 * train_set_length))\n",
    "\n",
    "        # Create a sampler for the train set (used in train_dataloader)\n",
    "        self.train_sampler = SubsetRandomSampler(indices[:split])\n",
    "\n",
    "        # Get the indices for the validation set (used in val_dataloader)\n",
    "        self.validation_indices = indices[split:]\n",
    "\n",
    "        # Create the train, validation and test sets\n",
    "        self.cifar100_train = datasets.CIFAR100(root=\"./data\", train=True, transform=train_set_transforms)\n",
    "        self.cifar100_validation = datasets.CIFAR100(root=\"./data\", train=True, transform=validation_set_transforms)\n",
    "        self.cifar100_test = datasets.CIFAR100(root=\"./data\", train=False, transform=test_set_transforms)\n",
    "\n",
    "        # Retrieve classes from the train set\n",
    "        self.classes = self.cifar100_train.classes\n",
    "        \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        cifar100_train = DataLoader(self.cifar100_train, batch_size=self.batch_size, sampler=self.train_sampler, num_workers=self.num_workers)\n",
    "        return cifar100_train\n",
    "\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        cifar100_validation = DataLoader(self.cifar100_validation, batch_size=self.batch_size, sampler=self.validation_indices, num_workers=self.num_workers)\n",
    "        return cifar100_validation\n",
    "\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        cifar100_test = DataLoader(self.cifar100_test, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "        return cifar100_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b388a",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15fa052",
   "metadata": {},
   "source": [
    "Then, we define a function to create the model. Here, we take the `resnet18` architecture but not pre-trained.\n",
    "We adapt it to our classification problem by modifying the first convolutional layer and the maxpool layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "858c2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"\n",
    "    Function to create the model.\n",
    "    \n",
    "    Takes in: -\n",
    "\n",
    "    Returns: model\n",
    "    \"\"\"\n",
    "    model = torchvision.models.resnet18(pretrained=False, num_classes=100)\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12d2cad",
   "metadata": {},
   "source": [
    "## Lightning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0833c2",
   "metadata": {},
   "source": [
    "The Lightning pipeline is where everything happens. It implements the following methods:\n",
    "- `configure_optimizers`\n",
    "- `forward`\n",
    "- `training_step`\n",
    "- `training_epoch_end`\n",
    "- `validation_step`\n",
    "- `validation_epoch_end`\n",
    "- `test_step`\n",
    "- `test_epoch_end`\n",
    "- `on_save_checkpoint`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "633e96c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR100ResNet(LightningModule):\n",
    "    def __init__(self, learning_rate, batch_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Save hyperparameters to the checkpoint\n",
    "        self.save_hyperparameters() \n",
    "\n",
    "        self.confmat = ConfusionMatrix(num_classes=100)\n",
    "        \n",
    "        # Creation of the model\n",
    "        self.model = create_model()\n",
    "\n",
    "        # Instantiation of the number of classes\n",
    "        self.n_classes = 100 \n",
    "   \n",
    "        # Instantiation of the learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Instantiation of the batch_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def configure_optimizers(self): \n",
    "        optimizer = torch.optim.SGD(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate,\n",
    "            momentum=0.9,\n",
    "            weight_decay=5e-4,\n",
    "        )\n",
    "        scheduler_dict = {\n",
    "            \"scheduler\": MultiStepLR(\n",
    "                optimizer,\n",
    "                milestones=[60,120,160],\n",
    "                gamma=0.2\n",
    "            ),\n",
    "            \"interval\": \"epoch\"\n",
    "        }        \n",
    "        #steps_per_epoch = int(np.ceil(45000 / self.batch_size))\n",
    "        #scheduler_dict = {\n",
    "            #\"scheduler\": OneCycleLR(\n",
    "            #    optimizer,\n",
    "            #    max_lr=0.1,\n",
    "            #    epochs=self.trainer.max_epochs,\n",
    "            #    steps_per_epoch=steps_per_epoch\n",
    "            #),\n",
    "            #\"interval\": \"step\"\n",
    "        #}\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler_dict}\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return F.log_softmax(out, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True)\n",
    "        return {\"inputs\":x, \"targets\":y, \"predictions\":preds, \"loss\":loss}    \n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        # Log weights and biases for all layers of the model\n",
    "        for name, params in self.named_parameters():\n",
    "            self.logger.experiment.add_histogram(name, params,self.current_epoch)\n",
    "        # Only after the first training epoch, log one of the training inputs as a figure and log the model graph\n",
    "        if self.current_epoch == 0:\n",
    "            image_samples = outputs[0][\"inputs\"][:10]\n",
    "            image_samples = image_samples.cpu()\n",
    "            image_samples_grid = make_grid(image_samples, normalize=True)\n",
    "            image_samples_grid = image_samples_grid.numpy()\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.imshow(np.transpose(image_samples_grid, (1, 2, 0)))\n",
    "            self.logger.experiment.add_figure(f\"Training sample normalized images\", fig)\n",
    "            input_sample = outputs[0][\"inputs\"][0]\n",
    "            input_sample = torch.unsqueeze(input_sample, 3)\n",
    "            input_sample = torch.permute(input_sample, (3,0,1,2))\n",
    "            self.logger.experiment.add_graph(self, input_sample)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "        self.log(f\"validation_loss\", loss, prog_bar=True)\n",
    "        self.log(f\"validation_acc\", acc, prog_bar=True)\n",
    "        return {\"inputs\":x, \"targets\":y, \"predictions\":preds, \"loss\":loss} \n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # Concatenate the targets of all batches\n",
    "        targets = torch.cat([output[\"targets\"] for output in outputs])\n",
    "        # Concatenate the predictions of all batches\n",
    "        preds = torch.cat([output[\"predictions\"] for output in outputs])\n",
    "        # Compute the confusion matrix\n",
    "        cm = self.confmat(preds, targets)\n",
    "        # Send it to the CPU\n",
    "        cm = cm.cpu()\n",
    "        # For each class\n",
    "        for class_id in range(self.n_classes):\n",
    "                # Calculate and log its prediction precision on the full validation set\n",
    "                precision = cm[class_id, class_id] / torch.sum(cm[:,class_id])\n",
    "                precision = round(precision.item()*100,1)\n",
    "                self.log(f\"validation_precision/{self.n_classes}\", precision)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "        self.log(f\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(f\"test_acc\", acc, prog_bar=True)\n",
    "        return {\"targets\":y, \"predictions\":preds}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        targets = torch.cat([output[\"targets\"] for output in outputs])\n",
    "        preds = torch.cat([output[\"predictions\"] for output in outputs])\n",
    "        # Compute the total prediction accuracy on the full test set\n",
    "        acc = accuracy(preds, targets)\n",
    "        # Compute the confusion matrix\n",
    "        cm = self.confmat(preds, targets)\n",
    "        # Send it to the CPU\n",
    "        cm = cm.cpu()\n",
    "        # Write the test set prediction performances to an output file\n",
    "        with open(\"test_set_predictions.txt\", \"w\") as f:\n",
    "            f.write(\"==================================================\\n\")\n",
    "            f.write(\"ACCURACY\\n\")\n",
    "            f.write(\"==================================================\\n\")\n",
    "            f.write(\"\\n\")            \n",
    "            f.write(f\"Total: {round(acc.item()*100, 1)}%\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"Per Class:\\n\")\n",
    "            f.write(\"Class - Accuracy (%)\\n\")\n",
    "            for class_id in range(self.n_classes):\n",
    "                precision = cm[class_id, class_id] / torch.sum(cm[:,class_id])            \n",
    "                precision = round(precision.item()*100, 1)\n",
    "                f.write(f\"{self.trainer.datamodule.classes[class_id]} - {precision}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"==================================================\\n\")\n",
    "            f.write(\"PREDICTIONS DETAIL\\n\")\n",
    "            f.write(\"==================================================\\n\")\n",
    "            f.write(\"Image index - Target class - Predicted class\\n\")\n",
    "            # Write the target class and the predicted class for each test image\n",
    "            for i in range(len(targets)):\n",
    "                f.write(f\"{i} - {self.trainer.datamodule.classes[targets[i]]} - {self.trainer.datamodule.classes[preds[i]]}\\n\")\n",
    "        \n",
    "    def on_save_checkpoint(self, checkpoint):\n",
    "        # Get the state_dict from self.model to get rid of the \"model.\" prefix\n",
    "        checkpoint[\"state_dict\"] = self.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b61c8c",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1624e07e",
   "metadata": {},
   "source": [
    "Finally, we set some of our hyper-parameters, instantiate the classes defined above as well as some callbacks (tensorboard logger, learning rate monitor, early stopping and checkpoint saving), and train and test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f9d7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoine/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:90: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=10)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 11.2 M\n",
      "---------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.881    Total estimated model params size (MB)\n",
      "/Users/antoine/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fca5e367dd425fac9510677699e731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter harmless waarnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", \".*Your `val_dataloader` has `shuffle=True`.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*Checkpoint directory.*\")\n",
    "\n",
    "# Print name of graphics card used\n",
    "gpus = min(0, torch.cuda.device_count())\n",
    "\n",
    "# Set number of workers (for dataloaders)\n",
    "num_workers = int(os.cpu_count() / 3)\n",
    "print(f\"Number of workers used: {num_workers}\")\n",
    "\n",
    "# Set maximum number of epochs to train for\n",
    "max_epochs = 200\n",
    "print(f\"Maximum number of epochs: {max_epochs}\")\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 256 if args.accelerator else 64\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "\n",
    "# Set the initial learning rate\n",
    "learning_rate = 0.1\n",
    "print(f\"Initial learning rate: {learning_rate}\")    \n",
    "\n",
    "# Instantiate the DataModule\n",
    "dm = datamodule.CIFAR100DataModule(batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "# Instantiate the logger\n",
    "tensorboard_logger = TensorBoardLogger(save_dir=\"logs\")\n",
    "\n",
    "# Instantiate early stopping based on epoch validation loss\n",
    "early_stopping = EarlyStopping(\"validation_loss\", patience=20, verbose=True)\n",
    "\n",
    "# Instantiate a learning rate monitor\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "# Instantiate a checkpoint callback\n",
    "checkpoint = ModelCheckpoint(\n",
    "                            dirpath=f\"./checkpoints/\",\n",
    "                            filename=\"{epoch}-{validation_loss:.2f}\",\n",
    "                            verbose=True,\n",
    "                            monitor=\"validation_loss\",\n",
    "                            save_last = False,\n",
    "                            save_top_k=1,      \n",
    "                            mode=\"min\",\n",
    "                            save_weights_only=True\n",
    "                            )\n",
    "\n",
    "# Instantiate the trainer\n",
    "trainer = Trainer(\n",
    "                gpus=gpus,\n",
    "                max_epochs=max_epochs, \n",
    "                logger=tensorboard_logger,\n",
    "                log_every_n_steps = 1,\n",
    "                callbacks=[lr_monitor, checkpoint]\n",
    "                ) \n",
    "\n",
    "# Instantiate the pipeline\n",
    "pipeline = pipeline.CIFAR100ResNet(learning_rate=learning_rate, batch_size=batch_size)  \n",
    "    \n",
    "# Fit the trainer on the training set\n",
    "trainer.fit(pipeline, dm)\n",
    "\n",
    "# Test on the test set\n",
    "trainer.test(pipeline, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e88d0",
   "metadata": {},
   "source": [
    "The model's performance metrics and the evolution of its hyperparameters, as well as images samples from the train set, can be visualised on the tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8665b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "251px",
    "width": "244px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
